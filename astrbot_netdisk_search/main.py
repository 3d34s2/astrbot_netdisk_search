from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Plain
import aiohttp
import json
import asyncio
from urllib.parse import quote, urljoin
import re

@register("netdisk_search", "deepseekR1", "ç½‘ç›˜èµ„æºæœç´¢æ’ä»¶", "1.0.0")
class NetdiskSearchPlugin(Star):
    def __init__(self, context: Context):
        super().__init__(context)
        self.api_url = "https://so.252035.xyz/api/search"
        self.debug_mode = True
        # ç½‘ç›˜åŸŸåæ˜ å°„
        self.cloud_domains = {
            'baidu': 'https://pan.baidu.com/',
            'aliyun': 'https://www.alipan.com/',
            'quark': 'https://pan.quark.cn/',
            'xunlei': 'https://pan.xunlei.com/',
            '115': 'https://115.com/',
            'uc': 'https://drive.uc.cn/',
            'tianyi': 'https://cloud.189.cn/',
            'mobile': 'https://caiyun.139.com/'
        }

    async def initialize(self):
        logger.info("ç½‘ç›˜èµ„æºæœç´¢æ’ä»¶å·²åŠ è½½")

    @filter.command("search", "æœç´¢ç½‘ç›˜èµ„æº")
    async def netdisk_search(self, event: AstrMessageEvent):
        message_chain = event.get_messages()
        keyword = self.extract_keyword(message_chain)
        
        if not keyword:
            await event.send(event.plain_result("âš ï¸ è¯·æä¾›æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š/search ç”µå½±å"))
            return

        await event.send(event.plain_result(f"ğŸ” æ­£åœ¨æœç´¢: {keyword}..."))
        await self.perform_search(event, keyword)

    def extract_keyword(self, message_chain) -> str:
        keyword = ""
        for msg in message_chain:
            if hasattr(msg, 'text'):
                text = msg.text.strip()
                if text.startswith('/search'):
                    keyword = text.replace('/search', '').strip()
                elif text.startswith('æœç´¢'):
                    keyword = text.replace('æœç´¢', '').strip()
                else:
                    keyword = text
                
                if keyword:
                    break
        return keyword

    async def perform_search(self, event: AstrMessageEvent, keyword: str):
        try:
            results = await self.call_search_api(keyword)
            
            if not results:
                await event.send(event.plain_result("âŒ æœç´¢å¤±è´¥æˆ–æœªæ‰¾åˆ°ç»“æœ"))
                return

            response = self.format_search_results(results, keyword)
            await event.send(event.plain_result(response))

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
            await event.send(event.plain_result(f"âŒ æœç´¢å¤±è´¥: {str(e)}"))

    async def call_search_api(self, keyword: str):
        """è°ƒç”¨æœç´¢API - ä½¿ç”¨GETè¯·æ±‚"""
        encoded_keyword = quote(keyword)
        url = f"{self.api_url}?kw={encoded_keyword}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            try:
                logger.debug(f"å‘é€GETè¯·æ±‚: {url}")
                
                async with session.get(
                    url,
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as response:
                    
                    if response.status != 200:
                        error_text = await response.text()
                        logger.error(f"APIé”™è¯¯: HTTP {response.status} - {error_text[:200]}")
                        raise Exception(f"æœåŠ¡å™¨é”™è¯¯: HTTP {response.status}")
                    
                    result = await response.json()
                    return result
                    
            except aiohttp.ClientError as e:
                logger.error(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
                raise Exception(f"ç½‘ç»œè¿æ¥å¤±è´¥: {str(e)}")
            except asyncio.TimeoutError:
                logger.error("è¯·æ±‚è¶…æ—¶")
                raise Exception("æœç´¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")

    def format_search_results(self, data: dict, keyword: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if data.get("code") != 0:
            error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
            return f"âŒ APIé”™è¯¯: {error_msg}"
        
        if not data.get("data"):
            return f"ğŸ” æœªæ‰¾åˆ°ä¸ã€{keyword}ã€ç›¸å…³çš„èµ„æº"
        
        result_data = data["data"]
        merged_results = result_data.get("merged_by_type", {})
        
        if not merged_results:
            return f"ğŸ” æœªæ‰¾åˆ°ä¸ã€{keyword}ã€ç›¸å…³çš„èµ„æº"

        lines = [
            f"ğŸ” æœç´¢ç»“æœ: {keyword}",
            f"ğŸ“Š æ€»å…±æ‰¾åˆ°: {result_data.get('total', 0)} æ¡èµ„æº",
            "=" * 40
        ]

        # ç»Ÿè®¡å„ç±»å‹èµ„æºæ•°é‡
        type_counts = {}
        total_results = 0
        
        for cloud_type, items in merged_results.items():
            if items and isinstance(items, list):
                count = len(items)
                type_counts[cloud_type] = count
                total_results += count

        if type_counts:
            lines.append("ğŸ“ èµ„æºç±»å‹åˆ†å¸ƒ:")
            for cloud_type, count in type_counts.items():
                lines.append(f"  â€¢ {self.get_type_name(cloud_type)}: {count}æ¡")
            lines.append("")

        # æ˜¾ç¤ºå‰å‡ ä¸ªèµ„æºçš„è¯¦ç»†ä¿¡æ¯
        displayed_count = 0
        max_display = 8  # å‡å°‘æ˜¾ç¤ºæ•°é‡ä»¥ç¡®ä¿å®Œæ•´é“¾æ¥

        # æŒ‰èµ„æºç±»å‹æ’åºæ˜¾ç¤º
        preferred_order = ['quark', 'aliyun', 'baidu', '115', 'xunlei']
        
        for cloud_type in preferred_order:
            if cloud_type in merged_results and displayed_count < max_display:
                items = merged_results[cloud_type]
                if items and isinstance(items, list):
                    displayed_count = self.add_cloud_type_results(
                        lines, cloud_type, items, displayed_count, max_display, keyword
                    )

        lines.append(f"ğŸ¯ å…±æ˜¾ç¤º {displayed_count} æ¡ç»“æœï¼Œæ€»è®¡ {total_results} æ¡èµ„æº")
        lines.append("ğŸ’¡ æç¤º: ç»“æœä»…ä¾›å‚è€ƒï¼Œè¯·éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„")
        lines.append("ğŸ”— å¤åˆ¶é“¾æ¥æ—¶è¯·ç¡®ä¿å®Œæ•´å¤åˆ¶")

        return "\n".join(lines)

    def add_cloud_type_results(self, lines, cloud_type, items, displayed_count, max_display, keyword):
        """æ·»åŠ ç‰¹å®šäº‘ç›˜ç±»å‹çš„æœç´¢ç»“æœ"""
        type_name = self.get_type_name(cloud_type)
        lines.append(f"ğŸ“¦ {type_name}èµ„æº:")

        count_in_type = 0
        max_per_type = 2  # æ¯ä¸ªç±»å‹æœ€å¤šæ˜¾ç¤º2æ¡ä»¥ç¡®ä¿å®Œæ•´é“¾æ¥

        for item in items:
            if displayed_count >= max_display or count_in_type >= max_per_type:
                break

            if isinstance(item, dict):
                # è·å–å®Œæ•´é“¾æ¥
                full_url = self.get_complete_url(item, cloud_type)
                title = self.generate_title(item, keyword, cloud_type)
                size = str(item.get('size', ''))
                time = str(item.get('time', ''))
                pwd = str(item.get('pwd', item.get('password', '')))
                
                lines.append(f"{displayed_count + 1}. {title}")
                if full_url:
                    lines.append(f"   ğŸ”— {full_url}")
                if size and size not in ['', 'æœªçŸ¥å¤§å°']:
                    lines.append(f"   ğŸ“¦ å¤§å°: {size}")
                if time and time not in ['', 'æœªçŸ¥æ—¶é—´']:
                    lines.append(f"   â° æ—¶é—´: {time}")
                if pwd and pwd not in ['', 'æ— å¯†ç ']:
                    lines.append(f"   ğŸ”‘ å¯†ç : {pwd}")
                lines.append("")
                
                displayed_count += 1
                count_in_type += 1

        return displayed_count

    def get_complete_url(self, item: dict, cloud_type: str) -> str:
        """è·å–å®Œæ•´çš„URL"""
        url = item.get('url') or item.get('link') or item.get('download_url') or ''
        
        if not url:
            return ""
        
        # å¦‚æœURLå·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if url.startswith(('http://', 'https://')):
            return url
        
        # å¦‚æœURLè¢«æˆªæ–­ï¼ˆåŒ…å«...ï¼‰ï¼Œå°è¯•é‡å»ºå®Œæ•´URL
        if '...' in url:
            # å°è¯•ä»åŸå§‹æ•°æ®ä¸­è·å–å®Œæ•´URL
            full_url = item.get('full_url') or item.get('complete_url') or ''
            if full_url and full_url.startswith(('http://', 'https://')):
                return full_url
            
            # å°è¯•ä¿®å¤è¢«æˆªæ–­çš„URL
            return self.reconstruct_url(url, cloud_type)
        
        # å¯¹äºç›¸å¯¹è·¯å¾„ï¼Œæ·»åŠ å¯¹åº”çš„åŸŸå
        if url.startswith('/'):
            base_url = self.cloud_domains.get(cloud_type, 'https://')
            return urljoin(base_url, url)
        
        # å…¶ä»–æƒ…å†µç›´æ¥è¿”å›
        return url

    def reconstruct_url(self, truncated_url: str, cloud_type: str) -> str:
        """é‡å»ºè¢«æˆªæ–­çš„URL"""
        # ç§»é™¤æˆªæ–­æ ‡è®°
        url = truncated_url.replace('...', '')
        
        # æ ¹æ®ä¸åŒç½‘ç›˜æ¨¡å¼é‡å»ºå®Œæ•´URL
        patterns = {
            'baidu': [
                r'(pan\.baidu\.com/s/[a-zA-Z0-9_-]+)',
                r'([a-zA-Z0-9_-]{23})'  # ç™¾åº¦åˆ†äº«ç é€šå¸¸æ˜¯23ä½
            ],
            'aliyun': [
                r'(alipan\.com/s/[a-zA-Z0-9]+)',
                r'(aliyundrive\.com/s/[a-zA-Z0-9]+)'
            ],
            'quark': [
                r'(pan\.quark\.cn/s/[a-zA-Z0-9]+)'
            ],
            'xunlei': [
                r'(pan\.xunlei\.com/s/[a-zA-Z0-9_-]+)'
            ],
            '115': [
                r'(115\.com/s/[a-zA-Z0-9_-]+)'
            ],
            'uc': [
                r'(drive\.uc\.cn/s/[a-zA-Z0-9]+)'
            ]
        }
        
        if cloud_type in patterns:
            for pattern in patterns[cloud_type]:
                match = re.search(pattern, url)
                if match:
                    found_part = match.group(1)
                    # æ·»åŠ httpsåè®®
                    if not found_part.startswith(('http://', 'https://')):
                        return f"https://{found_part}"
                    return found_part
        
        # é€šç”¨å¤„ç†ï¼šå°è¯•æå–å¯èƒ½çš„éƒ¨åˆ†å¹¶é‡å»º
        if any(domain in url for domain in ['baidu', 'aliyun', 'quark', 'xunlei', '115', 'uc']):
            # æå–åŸŸåå’Œè·¯å¾„
            domain_match = re.search(r'([a-zA-Z0-9.-]+\.(?:com|cn|net))/s/([a-zA-Z0-9_-]+)', url)
            if domain_match:
                domain = domain_match.group(1)
                path = domain_match.group(2)
                return f"https://{domain}/s/{path}"
        
        return truncated_url  # å¦‚æœæ— æ³•é‡å»ºï¼Œè¿”å›åŸå§‹ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰çš„URL

    def generate_title(self, item: dict, keyword: str, cloud_type: str) -> str:
        """ç”Ÿæˆèµ„æºæ ‡é¢˜"""
        title = item.get('title') or item.get('name') or item.get('filename') or ''
        
        if not title or title in ['æ— æ ‡é¢˜', 'æœªçŸ¥æ ‡é¢˜']:
            type_name = self.get_type_name(cloud_type)
            return f"{keyword} {type_name}èµ„æº"
        
        # æ¸…ç†æ ‡é¢˜
        title = re.sub(r'ã€.*?ã€‘|\[.*?\]|\(.*?\)', '', title)
        title = re.sub(r'\s+', ' ', title).strip()
        
        if len(title) > 30:
            return title[:27] + "..."
        return title

    def get_type_name(self, cloud_type: str) -> str:
        """è·å–ç½‘ç›˜ç±»å‹çš„ä¸­æ–‡åç§°"""
        type_map = {
            "baidu": "ç™¾åº¦ç½‘ç›˜", "aliyun": "é˜¿é‡Œäº‘ç›˜", "quark": "å¤¸å…‹ç½‘ç›˜",
            "tianyi": "å¤©ç¿¼äº‘ç›˜", "uc": "UCç½‘ç›˜", "mobile": "ç§»åŠ¨äº‘ç›˜",
            "115": "115ç½‘ç›˜", "xunlei": "è¿…é›·äº‘ç›˜"
        }
        return type_map.get(cloud_type, cloud_type)

    async def terminate(self):
        logger.info("ç½‘ç›˜èµ„æºæœç´¢æ’ä»¶å·²å¸è½½")
